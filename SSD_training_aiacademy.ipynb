{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "wf_Z8RBS798s",
    "outputId": "3fc08091-9d47-43fd-892f-eb8bf8c61916"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "6u4C5o3R7ZBK",
    "outputId": "a33c31e1-82cd-4474-c5c2-a935c7c01d13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "aqvlJIZL8iPH",
    "outputId": "3acd389e-150d-4d96-928b-46e82ee75fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.2\n",
      "  Using cached Keras-2.2.2-py2.py3-none-any.whl (299 kB)\n",
      "Requirement already satisfied: h5py in /Users/cyberbrain/anaconda3/lib/python3.7/site-packages (from keras==2.2.2) (2.9.0)\n",
      "Collecting keras-applications==1.0.4\n",
      "  Using cached Keras_Applications-1.0.4-py2.py3-none-any.whl (43 kB)\n",
      "Requirement already satisfied: pyyaml in /Users/cyberbrain/anaconda3/lib/python3.7/site-packages (from keras==2.2.2) (5.1)\n",
      "Collecting keras-preprocessing==1.0.2\n",
      "  Using cached Keras_Preprocessing-1.0.2-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/cyberbrain/anaconda3/lib/python3.7/site-packages (from keras==2.2.2) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/cyberbrain/anaconda3/lib/python3.7/site-packages (from keras==2.2.2) (1.16.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/cyberbrain/anaconda3/lib/python3.7/site-packages (from keras==2.2.2) (1.12.0)\n",
      "\u001b[31mERROR: plaidml-keras 0.6.4 has requirement keras==2.2.4, but you'll have keras 2.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.14.0 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.14.0 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras-applications, keras-preprocessing, keras\n",
      "  Attempting uninstall: keras-applications\n",
      "    Found existing installation: Keras-Applications 1.0.8\n",
      "    Uninstalling Keras-Applications-1.0.8:\n",
      "      Successfully uninstalled Keras-Applications-1.0.8\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.2.4\n",
      "    Uninstalling Keras-2.2.4:\n",
      "      Successfully uninstalled Keras-2.2.4\n",
      "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/Users/cyberbrain/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f-LUy0wY7ca2",
    "outputId": "3605ba8c-7983-47e2-a915-1efab9e9098c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "Ol-Uddbm2n8B",
    "outputId": "6d4416fb-b637-4001-ff15-3825787cdefb"
   },
   "outputs": [],
   "source": [
    "\"\"\"Some special pupropse layers for SSD.\"\"\"\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import InputSpec\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Normalize(Layer):\n",
    "    \"\"\"Normalization layer as described in ParseNet paper.\n",
    "\n",
    "    # Arguments\n",
    "        scale: Default feature scale.\n",
    "\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, channels, rows, cols)` if dim_ordering='th'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n",
    "\n",
    "    # Output shape\n",
    "        Same as input\n",
    "\n",
    "    # References\n",
    "        http://cs.unc.edu/~wliu/papers/parsenet.pdf\n",
    "\n",
    "    #TODO\n",
    "        Add possibility to have one scale for all features.\n",
    "    \"\"\"\n",
    "    def __init__(self, scale, **kwargs):\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            self.axis = 3\n",
    "        else:\n",
    "            self.axis = 1\n",
    "        self.scale = scale\n",
    "        super(Normalize, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (input_shape[self.axis],)\n",
    "        init_gamma = self.scale * np.ones(shape)\n",
    "        self.gamma = K.variable(init_gamma, name='{}_gamma'.format(self.name))\n",
    "        self.trainable_weights = [self.gamma]\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        output = K.l2_normalize(x, self.axis)\n",
    "        output *= self.gamma\n",
    "        return output\n",
    "\n",
    "\n",
    "class PriorBox(Layer):\n",
    "    \"\"\"Generate the prior boxes of designated sizes and aspect ratios.\n",
    "\n",
    "    # Arguments\n",
    "        img_size: Size of the input image as tuple (w, h).\n",
    "        min_size: Minimum box size in pixels.\n",
    "        max_size: Maximum box size in pixels.\n",
    "        aspect_ratios: List of aspect ratios of boxes.\n",
    "        flip: Whether to consider reverse aspect ratios.\n",
    "        variances: List of variances for x, y, w, h.\n",
    "        clip: Whether to clip the prior's coordinates\n",
    "            such that they are within [0, 1].\n",
    "\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(samples, channels, rows, cols)` if dim_ordering='th'\n",
    "        or 4D tensor with shape:\n",
    "        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n",
    "\n",
    "    # Output shape\n",
    "        3D tensor with shape:\n",
    "        (samples, num_boxes, 8)\n",
    "\n",
    "    # References\n",
    "        https://arxiv.org/abs/1512.02325\n",
    "\n",
    "    #TODO\n",
    "        Add possibility not to have variances.\n",
    "        Add Theano support\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, min_size, max_size=None, aspect_ratios=None,\n",
    "                 flip=True, variances=[0.1], clip=True, **kwargs):\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            self.waxis = 2\n",
    "            self.haxis = 1\n",
    "        else:\n",
    "            self.waxis = 3\n",
    "            self.haxis = 2\n",
    "        self.img_size = img_size\n",
    "        if min_size <= 0:\n",
    "            raise Exception('min_size must be positive.')\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "        self.aspect_ratios = [1.0]\n",
    "        if max_size:\n",
    "            if max_size < min_size:\n",
    "                raise Exception('max_size must be greater than min_size.')\n",
    "            self.aspect_ratios.append(1.0)\n",
    "        if aspect_ratios:\n",
    "            for ar in aspect_ratios:\n",
    "                if ar in self.aspect_ratios:\n",
    "                    continue\n",
    "                self.aspect_ratios.append(ar)\n",
    "                if flip:\n",
    "                    self.aspect_ratios.append(1.0 / ar)\n",
    "        self.variances = np.array(variances)\n",
    "        self.clip = True\n",
    "        super(PriorBox, self).__init__(**kwargs)\n",
    "\n",
    "    # def get_output_shape_for(self, input_shape):\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        num_priors_ = len(self.aspect_ratios)\n",
    "        layer_width = input_shape[self.waxis]\n",
    "        layer_height = input_shape[self.haxis]\n",
    "        num_boxes = num_priors_ * layer_width * layer_height\n",
    "        return (input_shape[0], num_boxes, 8)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if hasattr(x, '_keras_shape'):\n",
    "            input_shape = x._keras_shape\n",
    "        elif hasattr(K, 'int_shape'):\n",
    "            input_shape = K.int_shape(x)\n",
    "        layer_width = input_shape[self.waxis]\n",
    "        layer_height = input_shape[self.haxis]\n",
    "        img_width = self.img_size[0]\n",
    "        img_height = self.img_size[1]\n",
    "        # define prior boxes shapes\n",
    "        box_widths = []\n",
    "        box_heights = []\n",
    "        for ar in self.aspect_ratios:\n",
    "            if ar == 1 and len(box_widths) == 0:\n",
    "                box_widths.append(self.min_size)\n",
    "                box_heights.append(self.min_size)\n",
    "            elif ar == 1 and len(box_widths) > 0:\n",
    "                box_widths.append(np.sqrt(self.min_size * self.max_size))\n",
    "                box_heights.append(np.sqrt(self.min_size * self.max_size))\n",
    "            elif ar != 1:\n",
    "                box_widths.append(self.min_size * np.sqrt(ar))\n",
    "                box_heights.append(self.min_size / np.sqrt(ar))\n",
    "        box_widths = 0.5 * np.array(box_widths)\n",
    "        box_heights = 0.5 * np.array(box_heights)\n",
    "        # define centers of prior boxes\n",
    "        step_x = img_width / layer_width\n",
    "        step_y = img_height / layer_height\n",
    "        linx = np.linspace(0.5 * step_x, img_width - 0.5 * step_x,\n",
    "                           layer_width)\n",
    "        liny = np.linspace(0.5 * step_y, img_height - 0.5 * step_y,\n",
    "                           layer_height)\n",
    "        centers_x, centers_y = np.meshgrid(linx, liny)\n",
    "        centers_x = centers_x.reshape(-1, 1)\n",
    "        centers_y = centers_y.reshape(-1, 1)\n",
    "        # define xmin, ymin, xmax, ymax of prior boxes\n",
    "        num_priors_ = len(self.aspect_ratios)\n",
    "        prior_boxes = np.concatenate((centers_x, centers_y), axis=1)\n",
    "        prior_boxes = np.tile(prior_boxes, (1, 2 * num_priors_))\n",
    "        prior_boxes[:, ::4] -= box_widths\n",
    "        prior_boxes[:, 1::4] -= box_heights\n",
    "        prior_boxes[:, 2::4] += box_widths\n",
    "        prior_boxes[:, 3::4] += box_heights\n",
    "        prior_boxes[:, ::2] /= img_width\n",
    "        prior_boxes[:, 1::2] /= img_height\n",
    "        prior_boxes = prior_boxes.reshape(-1, 4)\n",
    "        if self.clip:\n",
    "            prior_boxes = np.minimum(np.maximum(prior_boxes, 0.0), 1.0)\n",
    "        # define variances\n",
    "        num_boxes = len(prior_boxes)\n",
    "        if len(self.variances) == 1:\n",
    "            variances = np.ones((num_boxes, 4)) * self.variances[0]\n",
    "        elif len(self.variances) == 4:\n",
    "            variances = np.tile(self.variances, (num_boxes, 1))\n",
    "        else:\n",
    "            raise Exception('Must provide one or four variances.')\n",
    "        prior_boxes = np.concatenate((prior_boxes, variances), axis=1)\n",
    "        prior_boxes_tensor = K.expand_dims(K.variable(prior_boxes), 0)\n",
    "        if K.backend() == 'tensorflow':\n",
    "            pattern = [tf.shape(x)[0], 1, 1]\n",
    "            prior_boxes_tensor = tf.tile(prior_boxes_tensor, pattern)\n",
    "        elif K.backend() == 'theano':\n",
    "            #TODO\n",
    "            pass\n",
    "        return prior_boxes_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKuN7c_L2nIW"
   },
   "outputs": [],
   "source": [
    "\"\"\"Keras implementation of SSD.\"\"\"\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.layers import AtrousConvolution2D\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.models import Model\n",
    "\n",
    "# from ssd_layers import Normalize\n",
    "# from ssd_layers import PriorBox\n",
    "\n",
    "\n",
    "def SSD300(input_shape, num_classes=21):\n",
    "    \"\"\"SSD300 architecture.\n",
    "\n",
    "    # Arguments\n",
    "        input_shape: Shape of the input image,\n",
    "            expected to be either (300, 300, 3) or (3, 300, 300)(not tested).\n",
    "        num_classes: Number of classes including background.\n",
    "\n",
    "    # References\n",
    "        https://arxiv.org/abs/1512.02325\n",
    "    \"\"\"\n",
    "    net = {}\n",
    "    # Block 1\n",
    "    input_tensor = input_tensor = Input(shape=input_shape)\n",
    "    img_size = (input_shape[1], input_shape[0])\n",
    "    net['input'] = input_tensor\n",
    "    net['conv1_1'] = Convolution2D(64, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv1_1')(net['input'])\n",
    "    net['conv1_2'] = Convolution2D(64, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv1_2')(net['conv1_1'])\n",
    "    net['pool1'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n",
    "                                name='pool1')(net['conv1_2'])\n",
    "    # Block 2\n",
    "    net['conv2_1'] = Convolution2D(128, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv2_1')(net['pool1'])\n",
    "    net['conv2_2'] = Convolution2D(128, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv2_2')(net['conv2_1'])\n",
    "    net['pool2'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n",
    "                                name='pool2')(net['conv2_2'])\n",
    "    # Block 3\n",
    "    net['conv3_1'] = Convolution2D(256, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv3_1')(net['pool2'])\n",
    "    net['conv3_2'] = Convolution2D(256, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv3_2')(net['conv3_1'])\n",
    "    net['conv3_3'] = Convolution2D(256, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv3_3')(net['conv3_2'])\n",
    "    net['pool3'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n",
    "                                name='pool3')(net['conv3_3'])\n",
    "    # Block 4\n",
    "    net['conv4_1'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv4_1')(net['pool3'])\n",
    "    net['conv4_2'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv4_2')(net['conv4_1'])\n",
    "    net['conv4_3'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv4_3')(net['conv4_2'])\n",
    "    net['pool4'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n",
    "                                name='pool4')(net['conv4_3'])\n",
    "    # Block 5\n",
    "    net['conv5_1'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv5_1')(net['pool4'])\n",
    "    net['conv5_2'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv5_2')(net['conv5_1'])\n",
    "    net['conv5_3'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv5_3')(net['conv5_2'])\n",
    "    net['pool5'] = MaxPooling2D((3, 3), strides=(1, 1), border_mode='same',\n",
    "                                name='pool5')(net['conv5_3'])\n",
    "    # FC6\n",
    "    net['fc6'] = AtrousConvolution2D(1024, 3, 3, atrous_rate=(6, 6),\n",
    "                                     activation='relu', border_mode='same',\n",
    "                                     name='fc6')(net['pool5'])\n",
    "    # x = Dropout(0.5, name='drop6')(x)\n",
    "    # FC7\n",
    "    net['fc7'] = Convolution2D(1024, 1, 1, activation='relu',\n",
    "                               border_mode='same', name='fc7')(net['fc6'])\n",
    "    # x = Dropout(0.5, name='drop7')(x)\n",
    "    # Block 6\n",
    "    net['conv6_1'] = Convolution2D(256, 1, 1, activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv6_1')(net['fc7'])\n",
    "    net['conv6_2'] = Convolution2D(512, 3, 3, subsample=(2, 2),\n",
    "                                   activation='relu', border_mode='same',\n",
    "                                   name='conv6_2')(net['conv6_1'])\n",
    "    # Block 7\n",
    "    net['conv7_1'] = Convolution2D(128, 1, 1, activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv7_1')(net['conv6_2'])\n",
    "    net['conv7_2'] = ZeroPadding2D()(net['conv7_1'])\n",
    "    net['conv7_2'] = Convolution2D(256, 3, 3, subsample=(2, 2),\n",
    "                                   activation='relu', border_mode='valid',\n",
    "                                   name='conv7_2')(net['conv7_2'])\n",
    "    # Block 8\n",
    "    net['conv8_1'] = Convolution2D(128, 1, 1, activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv8_1')(net['conv7_2'])\n",
    "    net['conv8_2'] = Convolution2D(256, 3, 3, subsample=(2, 2),\n",
    "                                   activation='relu', border_mode='same',\n",
    "                                   name='conv8_2')(net['conv8_1'])\n",
    "    # Last Pool\n",
    "    net['pool6'] = GlobalAveragePooling2D(name='pool6')(net['conv8_2'])\n",
    "    # Prediction from conv4_3\n",
    "    net['conv4_3_norm'] = Normalize(20, name='conv4_3_norm')(net['conv4_3'])\n",
    "    num_priors = 3\n",
    "    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n",
    "                      name='conv4_3_norm_mbox_loc')(net['conv4_3_norm'])\n",
    "    net['conv4_3_norm_mbox_loc'] = x\n",
    "    flatten = Flatten(name='conv4_3_norm_mbox_loc_flat')\n",
    "    net['conv4_3_norm_mbox_loc_flat'] = flatten(net['conv4_3_norm_mbox_loc'])\n",
    "    name = 'conv4_3_norm_mbox_conf'\n",
    "    if num_classes != 21:\n",
    "        name += '_{}'.format(num_classes)\n",
    "    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n",
    "                      name=name)(net['conv4_3_norm'])\n",
    "    net['conv4_3_norm_mbox_conf'] = x\n",
    "    flatten = Flatten(name='conv4_3_norm_mbox_conf_flat')\n",
    "    net['conv4_3_norm_mbox_conf_flat'] = flatten(net['conv4_3_norm_mbox_conf'])\n",
    "    priorbox = PriorBox(img_size, 30.0, aspect_ratios=[2],\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        name='conv4_3_norm_mbox_priorbox')\n",
    "    net['conv4_3_norm_mbox_priorbox'] = priorbox(net['conv4_3_norm'])\n",
    "    # Prediction from fc7\n",
    "    num_priors = 6\n",
    "    net['fc7_mbox_loc'] = Convolution2D(num_priors * 4, 3, 3,\n",
    "                                        border_mode='same',\n",
    "                                        name='fc7_mbox_loc')(net['fc7'])\n",
    "    flatten = Flatten(name='fc7_mbox_loc_flat')\n",
    "    net['fc7_mbox_loc_flat'] = flatten(net['fc7_mbox_loc'])\n",
    "    name = 'fc7_mbox_conf'\n",
    "    if num_classes != 21:\n",
    "        name += '_{}'.format(num_classes)\n",
    "    net['fc7_mbox_conf'] = Convolution2D(num_priors * num_classes, 3, 3,\n",
    "                                         border_mode='same',\n",
    "                                         name=name)(net['fc7'])\n",
    "    flatten = Flatten(name='fc7_mbox_conf_flat')\n",
    "    net['fc7_mbox_conf_flat'] = flatten(net['fc7_mbox_conf'])\n",
    "    priorbox = PriorBox(img_size, 60.0, max_size=114.0, aspect_ratios=[2, 3],\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        name='fc7_mbox_priorbox')\n",
    "    net['fc7_mbox_priorbox'] = priorbox(net['fc7'])\n",
    "    # Prediction from conv6_2\n",
    "    num_priors = 6\n",
    "    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n",
    "                      name='conv6_2_mbox_loc')(net['conv6_2'])\n",
    "    net['conv6_2_mbox_loc'] = x\n",
    "    flatten = Flatten(name='conv6_2_mbox_loc_flat')\n",
    "    net['conv6_2_mbox_loc_flat'] = flatten(net['conv6_2_mbox_loc'])\n",
    "    name = 'conv6_2_mbox_conf'\n",
    "    if num_classes != 21:\n",
    "        name += '_{}'.format(num_classes)\n",
    "    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n",
    "                      name=name)(net['conv6_2'])\n",
    "    net['conv6_2_mbox_conf'] = x\n",
    "    flatten = Flatten(name='conv6_2_mbox_conf_flat')\n",
    "    net['conv6_2_mbox_conf_flat'] = flatten(net['conv6_2_mbox_conf'])\n",
    "    priorbox = PriorBox(img_size, 114.0, max_size=168.0, aspect_ratios=[2, 3],\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        name='conv6_2_mbox_priorbox')\n",
    "    net['conv6_2_mbox_priorbox'] = priorbox(net['conv6_2'])\n",
    "    # Prediction from conv7_2\n",
    "    num_priors = 6\n",
    "    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n",
    "                      name='conv7_2_mbox_loc')(net['conv7_2'])\n",
    "    net['conv7_2_mbox_loc'] = x\n",
    "    flatten = Flatten(name='conv7_2_mbox_loc_flat')\n",
    "    net['conv7_2_mbox_loc_flat'] = flatten(net['conv7_2_mbox_loc'])\n",
    "    name = 'conv7_2_mbox_conf'\n",
    "    if num_classes != 21:\n",
    "        name += '_{}'.format(num_classes)\n",
    "    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n",
    "                      name=name)(net['conv7_2'])\n",
    "    net['conv7_2_mbox_conf'] = x\n",
    "    flatten = Flatten(name='conv7_2_mbox_conf_flat')\n",
    "    net['conv7_2_mbox_conf_flat'] = flatten(net['conv7_2_mbox_conf'])\n",
    "    priorbox = PriorBox(img_size, 168.0, max_size=222.0, aspect_ratios=[2, 3],\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        name='conv7_2_mbox_priorbox')\n",
    "    net['conv7_2_mbox_priorbox'] = priorbox(net['conv7_2'])\n",
    "    # Prediction from conv8_2\n",
    "    num_priors = 6\n",
    "    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n",
    "                      name='conv8_2_mbox_loc')(net['conv8_2'])\n",
    "    net['conv8_2_mbox_loc'] = x\n",
    "    flatten = Flatten(name='conv8_2_mbox_loc_flat')\n",
    "    net['conv8_2_mbox_loc_flat'] = flatten(net['conv8_2_mbox_loc'])\n",
    "    name = 'conv8_2_mbox_conf'\n",
    "    if num_classes != 21:\n",
    "        name += '_{}'.format(num_classes)\n",
    "    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n",
    "                      name=name)(net['conv8_2'])\n",
    "    net['conv8_2_mbox_conf'] = x\n",
    "    flatten = Flatten(name='conv8_2_mbox_conf_flat')\n",
    "    net['conv8_2_mbox_conf_flat'] = flatten(net['conv8_2_mbox_conf'])\n",
    "    priorbox = PriorBox(img_size, 222.0, max_size=276.0, aspect_ratios=[2, 3],\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        name='conv8_2_mbox_priorbox')\n",
    "    net['conv8_2_mbox_priorbox'] = priorbox(net['conv8_2'])\n",
    "    # Prediction from pool6\n",
    "    num_priors = 6\n",
    "    x = Dense(num_priors * 4, name='pool6_mbox_loc_flat')(net['pool6'])\n",
    "    net['pool6_mbox_loc_flat'] = x\n",
    "    name = 'pool6_mbox_conf_flat'\n",
    "    if num_classes != 21:\n",
    "        name += '_{}'.format(num_classes)\n",
    "    x = Dense(num_priors * num_classes, name=name)(net['pool6'])\n",
    "    net['pool6_mbox_conf_flat'] = x\n",
    "    priorbox = PriorBox(img_size, 276.0, max_size=330.0, aspect_ratios=[2, 3],\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        name='pool6_mbox_priorbox')\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        target_shape = (1, 1, 256)\n",
    "    else:\n",
    "        target_shape = (256, 1, 1)\n",
    "    net['pool6_reshaped'] = Reshape(target_shape,\n",
    "                                    name='pool6_reshaped')(net['pool6'])\n",
    "    net['pool6_mbox_priorbox'] = priorbox(net['pool6_reshaped'])\n",
    "    # Gather all predictions\n",
    "    net['mbox_loc'] = concatenate([net['conv4_3_norm_mbox_loc_flat'],\n",
    "                             net['fc7_mbox_loc_flat'],\n",
    "                             net['conv6_2_mbox_loc_flat'],\n",
    "                             net['conv7_2_mbox_loc_flat'],\n",
    "                             net['conv8_2_mbox_loc_flat'],\n",
    "                             net['pool6_mbox_loc_flat']],\n",
    "                             axis=1, name='mbox_loc')\n",
    "    net['mbox_conf'] = concatenate([net['conv4_3_norm_mbox_conf_flat'],\n",
    "                              net['fc7_mbox_conf_flat'],\n",
    "                              net['conv6_2_mbox_conf_flat'],\n",
    "                              net['conv7_2_mbox_conf_flat'],\n",
    "                              net['conv8_2_mbox_conf_flat'],\n",
    "                              net['pool6_mbox_conf_flat']],\n",
    "                             axis=1, name='mbox_conf')\n",
    "    net['mbox_priorbox'] = concatenate([net['conv4_3_norm_mbox_priorbox'],\n",
    "                                  net['fc7_mbox_priorbox'],\n",
    "                                  net['conv6_2_mbox_priorbox'],\n",
    "                                  net['conv7_2_mbox_priorbox'],\n",
    "                                  net['conv8_2_mbox_priorbox'],\n",
    "                                  net['pool6_mbox_priorbox']],\n",
    "                                 axis=1,\n",
    "                                 name='mbox_priorbox')\n",
    "    if hasattr(net['mbox_loc'], '_keras_shape'):\n",
    "        num_boxes = net['mbox_loc']._keras_shape[-1] // 4\n",
    "    elif hasattr(net['mbox_loc'], 'int_shape'):\n",
    "        num_boxes = K.int_shape(net['mbox_loc'])[-1] // 4\n",
    "    net['mbox_loc'] = Reshape((num_boxes, 4),\n",
    "                              name='mbox_loc_final')(net['mbox_loc'])\n",
    "    net['mbox_conf'] = Reshape((num_boxes, num_classes),\n",
    "                               name='mbox_conf_logits')(net['mbox_conf'])\n",
    "    net['mbox_conf'] = Activation('softmax',\n",
    "                                  name='mbox_conf_final')(net['mbox_conf'])\n",
    "    net['predictions'] = concatenate([net['mbox_loc'],\n",
    "                               net['mbox_conf'],\n",
    "                               net['mbox_priorbox']],\n",
    "                               axis=2,\n",
    "                               name='predictions')\n",
    "    model = Model(net['input'], net['predictions'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mSHri4lg2n_Y"
   },
   "outputs": [],
   "source": [
    "\"\"\"Some utils for SSD.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class BBoxUtility(object):\n",
    "    \"\"\"Utility class to do some stuff with bounding boxes and priors.\n",
    "\n",
    "    # Arguments\n",
    "        num_classes: Number of classes including background.\n",
    "        priors: Priors and variances, numpy tensor of shape (num_priors, 8),\n",
    "            priors[i] = [xmin, ymin, xmax, ymax, varxc, varyc, varw, varh].\n",
    "        overlap_threshold: Threshold to assign box to a prior.\n",
    "        nms_thresh: Nms threshold.\n",
    "        top_k: Number of total bboxes to be kept per image after nms step.\n",
    "\n",
    "    # References\n",
    "        https://arxiv.org/abs/1512.02325\n",
    "    \"\"\"\n",
    "    # TODO add setter methods for nms_thresh and top_K\n",
    "    def __init__(self, num_classes, priors=None, overlap_threshold=0.5,\n",
    "                 nms_thresh=0.45, top_k=400):\n",
    "        self.num_classes = num_classes\n",
    "        self.priors = priors\n",
    "        self.num_priors = 0 if priors is None else len(priors)\n",
    "        self.overlap_threshold = overlap_threshold\n",
    "        self._nms_thresh = nms_thresh\n",
    "        self._top_k = top_k\n",
    "        self.boxes = tf.placeholder(dtype='float32', shape=(None, 4))\n",
    "        self.scores = tf.placeholder(dtype='float32', shape=(None,))\n",
    "        self.nms = tf.image.non_max_suppression(self.boxes, self.scores,\n",
    "                                                self._top_k,\n",
    "                                                iou_threshold=self._nms_thresh)\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "    @property\n",
    "    def nms_thresh(self):\n",
    "        return self._nms_thresh\n",
    "\n",
    "    @nms_thresh.setter\n",
    "    def nms_thresh(self, value):\n",
    "        self._nms_thresh = value\n",
    "        self.nms = tf.image.non_max_suppression(self.boxes, self.scores,\n",
    "                                                self._top_k,\n",
    "                                                iou_threshold=self._nms_thresh)\n",
    "\n",
    "    @property\n",
    "    def top_k(self):\n",
    "        return self._top_k\n",
    "\n",
    "    @top_k.setter\n",
    "    def top_k(self, value):\n",
    "        self._top_k = value\n",
    "        self.nms = tf.image.non_max_suppression(self.boxes, self.scores,\n",
    "                                                self._top_k,\n",
    "                                                iou_threshold=self._nms_thresh)\n",
    "\n",
    "    def iou(self, box):\n",
    "        \"\"\"Compute intersection over union for the box with all priors.\n",
    "\n",
    "        # Arguments\n",
    "            box: Box, numpy tensor of shape (4,).\n",
    "\n",
    "        # Return\n",
    "            iou: Intersection over union,\n",
    "                numpy tensor of shape (num_priors).\n",
    "        \"\"\"\n",
    "        # compute intersection\n",
    "        inter_upleft = np.maximum(self.priors[:, :2], box[:2])\n",
    "        inter_botright = np.minimum(self.priors[:, 2:4], box[2:])\n",
    "        inter_wh = inter_botright - inter_upleft\n",
    "        inter_wh = np.maximum(inter_wh, 0)\n",
    "        inter = inter_wh[:, 0] * inter_wh[:, 1]\n",
    "        # compute union\n",
    "        area_pred = (box[2] - box[0]) * (box[3] - box[1])\n",
    "        area_gt = (self.priors[:, 2] - self.priors[:, 0])\n",
    "        area_gt *= (self.priors[:, 3] - self.priors[:, 1])\n",
    "        union = area_pred + area_gt - inter\n",
    "        # compute iou\n",
    "        iou = inter / union\n",
    "        return iou\n",
    "\n",
    "    def encode_box(self, box, return_iou=True):\n",
    "        \"\"\"Encode box for training, do it only for assigned priors.\n",
    "\n",
    "        # Arguments\n",
    "            box: Box, numpy tensor of shape (4,).\n",
    "            return_iou: Whether to concat iou to encoded values.\n",
    "\n",
    "        # Return\n",
    "            encoded_box: Tensor with encoded box\n",
    "                numpy tensor of shape (num_priors, 4 + int(return_iou)).\n",
    "        \"\"\"\n",
    "        iou = self.iou(box)\n",
    "        encoded_box = np.zeros((self.num_priors, 4 + return_iou))\n",
    "        assign_mask = iou > self.overlap_threshold\n",
    "        if not assign_mask.any():\n",
    "            assign_mask[iou.argmax()] = True\n",
    "        if return_iou:\n",
    "            encoded_box[:, -1][assign_mask] = iou[assign_mask]\n",
    "        assigned_priors = self.priors[assign_mask]\n",
    "        box_center = 0.5 * (box[:2] + box[2:])\n",
    "        box_wh = box[2:] - box[:2]\n",
    "        assigned_priors_center = 0.5 * (assigned_priors[:, :2] +\n",
    "                                        assigned_priors[:, 2:4])\n",
    "        assigned_priors_wh = (assigned_priors[:, 2:4] -\n",
    "                              assigned_priors[:, :2])\n",
    "        # we encode variance\n",
    "        encoded_box[:, :2][assign_mask] = box_center - assigned_priors_center\n",
    "        encoded_box[:, :2][assign_mask] /= assigned_priors_wh\n",
    "        encoded_box[:, :2][assign_mask] /= assigned_priors[:, -4:-2]\n",
    "        encoded_box[:, 2:4][assign_mask] = np.log(box_wh /\n",
    "                                                  assigned_priors_wh)\n",
    "        encoded_box[:, 2:4][assign_mask] /= assigned_priors[:, -2:]\n",
    "        return encoded_box.ravel()\n",
    "\n",
    "    def assign_boxes(self, boxes):\n",
    "        \"\"\"Assign boxes to priors for training.\n",
    "\n",
    "        # Arguments\n",
    "            boxes: Box, numpy tensor of shape (num_boxes, 4 + num_classes),\n",
    "                num_classes without background.\n",
    "\n",
    "        # Return\n",
    "            assignment: Tensor with assigned boxes,\n",
    "                numpy tensor of shape (num_boxes, 4 + num_classes + 8),\n",
    "                priors in ground truth are fictitious,\n",
    "                assignment[:, -8] has 1 if prior should be penalized\n",
    "                    or in other words is assigned to some ground truth box,\n",
    "                assignment[:, -7:] are all 0. See loss for more details.\n",
    "        \"\"\"\n",
    "        assignment = np.zeros((self.num_priors, 4 + self.num_classes + 8))\n",
    "        assignment[:, 4] = 1.0\n",
    "        if len(boxes) == 0:\n",
    "            return assignment\n",
    "        encoded_boxes = np.apply_along_axis(self.encode_box, 1, boxes[:, :4])\n",
    "        encoded_boxes = encoded_boxes.reshape(-1, self.num_priors, 5)\n",
    "        best_iou = encoded_boxes[:, :, -1].max(axis=0)\n",
    "        best_iou_idx = encoded_boxes[:, :, -1].argmax(axis=0)\n",
    "        best_iou_mask = best_iou > 0\n",
    "        best_iou_idx = best_iou_idx[best_iou_mask]\n",
    "        assign_num = len(best_iou_idx)\n",
    "        encoded_boxes = encoded_boxes[:, best_iou_mask, :]\n",
    "        assignment[:, :4][best_iou_mask] = encoded_boxes[best_iou_idx,\n",
    "                                                         np.arange(assign_num),\n",
    "                                                         :4]\n",
    "        assignment[:, 4][best_iou_mask] = 0\n",
    "        assignment[:, 5:-8][best_iou_mask] = boxes[best_iou_idx, 4:]\n",
    "        assignment[:, -8][best_iou_mask] = 1\n",
    "        return assignment\n",
    "\n",
    "    def decode_boxes(self, mbox_loc, mbox_priorbox, variances):\n",
    "        \"\"\"Convert bboxes from local predictions to shifted priors.\n",
    "\n",
    "        # Arguments\n",
    "            mbox_loc: Numpy array of predicted locations.\n",
    "            mbox_priorbox: Numpy array of prior boxes.\n",
    "            variances: Numpy array of variances.\n",
    "\n",
    "        # Return\n",
    "            decode_bbox: Shifted priors.\n",
    "        \"\"\"\n",
    "        prior_width = mbox_priorbox[:, 2] - mbox_priorbox[:, 0]\n",
    "        prior_height = mbox_priorbox[:, 3] - mbox_priorbox[:, 1]\n",
    "        prior_center_x = 0.5 * (mbox_priorbox[:, 2] + mbox_priorbox[:, 0])\n",
    "        prior_center_y = 0.5 * (mbox_priorbox[:, 3] + mbox_priorbox[:, 1])\n",
    "        decode_bbox_center_x = mbox_loc[:, 0] * prior_width * variances[:, 0]\n",
    "        decode_bbox_center_x += prior_center_x\n",
    "        decode_bbox_center_y = mbox_loc[:, 1] * prior_width * variances[:, 1]\n",
    "        decode_bbox_center_y += prior_center_y\n",
    "        decode_bbox_width = np.exp(mbox_loc[:, 2] * variances[:, 2])\n",
    "        decode_bbox_width *= prior_width\n",
    "        decode_bbox_height = np.exp(mbox_loc[:, 3] * variances[:, 3])\n",
    "        decode_bbox_height *= prior_height\n",
    "        decode_bbox_xmin = decode_bbox_center_x - 0.5 * decode_bbox_width\n",
    "        decode_bbox_ymin = decode_bbox_center_y - 0.5 * decode_bbox_height\n",
    "        decode_bbox_xmax = decode_bbox_center_x + 0.5 * decode_bbox_width\n",
    "        decode_bbox_ymax = decode_bbox_center_y + 0.5 * decode_bbox_height\n",
    "        decode_bbox = np.concatenate((decode_bbox_xmin[:, None],\n",
    "                                      decode_bbox_ymin[:, None],\n",
    "                                      decode_bbox_xmax[:, None],\n",
    "                                      decode_bbox_ymax[:, None]), axis=-1)\n",
    "        decode_bbox = np.minimum(np.maximum(decode_bbox, 0.0), 1.0)\n",
    "        return decode_bbox\n",
    "\n",
    "    def detection_out(self, predictions, background_label_id=0, keep_top_k=200,\n",
    "                      confidence_threshold=0.01):\n",
    "        \"\"\"Do non maximum suppression (nms) on prediction results.\n",
    "\n",
    "        # Arguments\n",
    "            predictions: Numpy array of predicted values.\n",
    "            num_classes: Number of classes for prediction.\n",
    "            background_label_id: Label of background class.\n",
    "            keep_top_k: Number of total bboxes to be kept per image\n",
    "                after nms step.\n",
    "            confidence_threshold: Only consider detections,\n",
    "                whose confidences are larger than a threshold.\n",
    "\n",
    "        # Return\n",
    "            results: List of predictions for every picture. Each prediction is:\n",
    "                [label, confidence, xmin, ymin, xmax, ymax]\n",
    "        \"\"\"\n",
    "        mbox_loc = predictions[:, :, :4]\n",
    "        variances = predictions[:, :, -4:]\n",
    "        mbox_priorbox = predictions[:, :, -8:-4]\n",
    "        mbox_conf = predictions[:, :, 4:-8]\n",
    "        results = []\n",
    "        for i in range(len(mbox_loc)):\n",
    "            results.append([])\n",
    "            decode_bbox = self.decode_boxes(mbox_loc[i],\n",
    "                                            mbox_priorbox[i], variances[i])\n",
    "            for c in range(self.num_classes):\n",
    "                if c == background_label_id:\n",
    "                    continue\n",
    "                c_confs = mbox_conf[i, :, c]\n",
    "                c_confs_m = c_confs > confidence_threshold\n",
    "                if len(c_confs[c_confs_m]) > 0:\n",
    "                    boxes_to_process = decode_bbox[c_confs_m]\n",
    "                    confs_to_process = c_confs[c_confs_m]\n",
    "                    feed_dict = {self.boxes: boxes_to_process,\n",
    "                                 self.scores: confs_to_process}\n",
    "                    idx = self.sess.run(self.nms, feed_dict=feed_dict)\n",
    "                    good_boxes = boxes_to_process[idx]\n",
    "                    confs = confs_to_process[idx][:, None]\n",
    "                    labels = c * np.ones((len(idx), 1))\n",
    "                    c_pred = np.concatenate((labels, confs, good_boxes),\n",
    "                                            axis=1)\n",
    "                    results[-1].extend(c_pred)\n",
    "            if len(results[-1]) > 0:\n",
    "                results[-1] = np.array(results[-1])\n",
    "                argsort = np.argsort(results[-1][:, 1])[::-1]\n",
    "                results[-1] = results[-1][argsort]\n",
    "                results[-1] = results[-1][:keep_top_k]\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IHsdvNs62oCT",
    "outputId": "2d1eecbf-7fe7-488c-deac-1fe9bf0f715e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.1.0 in /Users/cyberbrain/anaconda3/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /Users/cyberbrain/anaconda3/lib/python3.7/site-packages (from scipy==1.1.0) (1.16.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/Users/cyberbrain/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy==1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "44wQMlPe2oFF",
    "outputId": "81dd3830-9792-4c12-f9ef-206e21608a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /Users/cyberbrain/anaconda3/lib/python3.7/site-packages (2.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/Users/cyberbrain/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neE612UM5kaE"
   },
   "outputs": [],
   "source": [
    "# from scipy.misc import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjiP0hfLCeTo"
   },
   "outputs": [],
   "source": [
    "\"\"\"SSD training utils.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class MultiboxLoss(object):\n",
    "    \"\"\"Multibox loss with some helper functions.\n",
    "\n",
    "    # Arguments\n",
    "        num_classes: Number of classes including background.\n",
    "        alpha: Weight of L1-smooth loss.\n",
    "        neg_pos_ratio: Max ratio of negative to positive boxes in loss.\n",
    "        background_label_id: Id of background label.\n",
    "        negatives_for_hard: Number of negative boxes to consider\n",
    "            it there is no positive boxes in batch.\n",
    "\n",
    "    # References\n",
    "        https://arxiv.org/abs/1512.02325\n",
    "\n",
    "    # TODO\n",
    "        Add possibility for background label id be not zero\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, alpha=1.0, neg_pos_ratio=3.0,\n",
    "                 background_label_id=0, negatives_for_hard=100.0):\n",
    "        self.num_classes = num_classes\n",
    "        self.alpha = alpha\n",
    "        self.neg_pos_ratio = neg_pos_ratio\n",
    "        if background_label_id != 0:\n",
    "            raise Exception('Only 0 as background label id is supported')\n",
    "        self.background_label_id = background_label_id\n",
    "        self.negatives_for_hard = negatives_for_hard\n",
    "\n",
    "    def _l1_smooth_loss(self, y_true, y_pred):\n",
    "        \"\"\"Compute L1-smooth loss.\n",
    "\n",
    "        # Arguments\n",
    "            y_true: Ground truth bounding boxes,\n",
    "                tensor of shape (?, num_boxes, 4).\n",
    "            y_pred: Predicted bounding boxes,\n",
    "                tensor of shape (?, num_boxes, 4).\n",
    "\n",
    "        # Returns\n",
    "            l1_loss: L1-smooth loss, tensor of shape (?, num_boxes).\n",
    "\n",
    "        # References\n",
    "            https://arxiv.org/abs/1504.08083\n",
    "        \"\"\"\n",
    "        abs_loss = tf.abs(y_true - y_pred)\n",
    "        sq_loss = 0.5 * (y_true - y_pred)**2\n",
    "        l1_loss = tf.where(tf.less(abs_loss, 1.0), sq_loss, abs_loss - 0.5)\n",
    "        return tf.reduce_sum(l1_loss, -1)\n",
    "\n",
    "    def _softmax_loss(self, y_true, y_pred):\n",
    "        \"\"\"Compute softmax loss.\n",
    "\n",
    "        # Arguments\n",
    "            y_true: Ground truth targets,\n",
    "                tensor of shape (?, num_boxes, num_classes).\n",
    "            y_pred: Predicted logits,\n",
    "                tensor of shape (?, num_boxes, num_classes).\n",
    "\n",
    "        # Returns\n",
    "            softmax_loss: Softmax loss, tensor of shape (?, num_boxes).\n",
    "        \"\"\"\n",
    "        y_pred = tf.maximum(tf.minimum(y_pred, 1 - 1e-15), 1e-15)\n",
    "        softmax_loss = -tf.reduce_sum(y_true * tf.log(y_pred),\n",
    "                                      axis=-1)\n",
    "        return softmax_loss\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        \"\"\"Compute mutlibox loss.\n",
    "\n",
    "        # Arguments\n",
    "            y_true: Ground truth targets,\n",
    "                tensor of shape (?, num_boxes, 4 + num_classes + 8),\n",
    "                priors in ground truth are fictitious,\n",
    "                y_true[:, :, -8] has 1 if prior should be penalized\n",
    "                    or in other words is assigned to some ground truth box,\n",
    "                y_true[:, :, -7:] are all 0.\n",
    "            y_pred: Predicted logits,\n",
    "                tensor of shape (?, num_boxes, 4 + num_classes + 8).\n",
    "\n",
    "        # Returns\n",
    "            loss: Loss for prediction, tensor of shape (?,).\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(y_true)[0]\n",
    "        num_boxes = tf.to_float(tf.shape(y_true)[1])\n",
    "\n",
    "        # loss for all priors\n",
    "        conf_loss = self._softmax_loss(y_true[:, :, 4:-8],\n",
    "                                       y_pred[:, :, 4:-8])\n",
    "        loc_loss = self._l1_smooth_loss(y_true[:, :, :4],\n",
    "                                        y_pred[:, :, :4])\n",
    "\n",
    "        # get positives loss\n",
    "        num_pos = tf.reduce_sum(y_true[:, :, -8], axis=-1)\n",
    "        pos_loc_loss = tf.reduce_sum(loc_loss * y_true[:, :, -8],\n",
    "                                     axis=1)\n",
    "        pos_conf_loss = tf.reduce_sum(conf_loss * y_true[:, :, -8],\n",
    "                                      axis=1)\n",
    "\n",
    "        # get negatives loss, we penalize only confidence here\n",
    "        num_neg = tf.minimum(self.neg_pos_ratio * num_pos,\n",
    "                             num_boxes - num_pos)\n",
    "        pos_num_neg_mask = tf.greater(num_neg, 0)\n",
    "        has_min = tf.to_float(tf.reduce_any(pos_num_neg_mask))\n",
    "        num_neg = tf.concat(axis=0, values=[num_neg,\n",
    "                                [(1 - has_min) * self.negatives_for_hard]])\n",
    "        num_neg_batch = tf.reduce_min(tf.boolean_mask(num_neg,\n",
    "                                                      tf.greater(num_neg, 0)))\n",
    "        num_neg_batch = tf.to_int32(num_neg_batch)\n",
    "        confs_start = 4 + self.background_label_id + 1\n",
    "        confs_end = confs_start + self.num_classes - 1\n",
    "        max_confs = tf.reduce_max(y_pred[:, :, confs_start:confs_end],\n",
    "                                  axis=2)\n",
    "        _, indices = tf.nn.top_k(max_confs * (1 - y_true[:, :, -8]),\n",
    "                                 k=num_neg_batch)\n",
    "        batch_idx = tf.expand_dims(tf.range(0, batch_size), 1)\n",
    "        batch_idx = tf.tile(batch_idx, (1, num_neg_batch))\n",
    "        full_indices = (tf.reshape(batch_idx, [-1]) * tf.to_int32(num_boxes) +\n",
    "                        tf.reshape(indices, [-1]))\n",
    "        # full_indices = tf.concat(2, [tf.expand_dims(batch_idx, 2),\n",
    "        #                              tf.expand_dims(indices, 2)])\n",
    "        # neg_conf_loss = tf.gather_nd(conf_loss, full_indices)\n",
    "        neg_conf_loss = tf.gather(tf.reshape(conf_loss, [-1]),\n",
    "                                  full_indices)\n",
    "        neg_conf_loss = tf.reshape(neg_conf_loss,\n",
    "                                   [batch_size, num_neg_batch])\n",
    "        neg_conf_loss = tf.reduce_sum(neg_conf_loss, axis=1)\n",
    "\n",
    "        # loss is sum of positives and negatives\n",
    "        total_loss = pos_conf_loss + neg_conf_loss\n",
    "        total_loss /= (num_pos + tf.to_float(num_neg_batch))\n",
    "        num_pos = tf.where(tf.not_equal(num_pos, 0), num_pos,\n",
    "                            tf.ones_like(num_pos))\n",
    "        total_loss += (self.alpha * pos_loc_loss) / num_pos\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bg4sErAl0s0l"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from random import shuffle\n",
    "# pip install scipy==1.1.0\n",
    "# from scipy.misc import imread\n",
    "# pip install imageio\n",
    "from imageio import imread\n",
    "from scipy.misc import imresize\n",
    "import tensorflow as tf\n",
    "\n",
    "# from ssd import SSD300\n",
    "# from ssd_training import MultiboxLoss\n",
    "# from ssd_utils import BBoxUtility\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# 21\n",
    "NUM_CLASSES = 21 #4\n",
    "input_shape = (300, 300, 3)\n",
    "\n",
    "priors = pickle.load(open('./prior_boxes_ssd300.pkl', 'rb'))\n",
    "\n",
    "bbox_util = BBoxUtility(NUM_CLASSES, priors)\n",
    "\n",
    "# gt = pickle.load(open('gt_pascal.pkl', 'rb'))\n",
    "\n",
    "gt = pickle.load(open('./dog_cat.pkl', 'rb'))\n",
    "\n",
    "keys = sorted(gt.keys())\n",
    "num_train = int(round(0.8 * len(keys)))\n",
    "train_keys = keys[:num_train]\n",
    "val_keys = keys[num_train:]\n",
    "num_val = len(val_keys)\n",
    "\n",
    "class Generator(object):\n",
    "    def __init__(self, gt, bbox_util,\n",
    "                 batch_size, path_prefix,\n",
    "                 train_keys, val_keys, image_size,\n",
    "                 saturation_var=0.5,\n",
    "                 brightness_var=0.5,\n",
    "                 contrast_var=0.5,\n",
    "                 lighting_std=0.5,\n",
    "                 hflip_prob=0.5,\n",
    "                 vflip_prob=0.5,\n",
    "                 do_crop=True,\n",
    "                 crop_area_range=[0.75, 1.0],\n",
    "                 aspect_ratio_range=[3./4., 4./3.]):\n",
    "        self.gt = gt\n",
    "        self.bbox_util = bbox_util\n",
    "        self.batch_size = batch_size\n",
    "        self.path_prefix = path_prefix\n",
    "        self.train_keys = train_keys\n",
    "        self.val_keys = val_keys\n",
    "        self.train_batches = len(train_keys)\n",
    "        self.val_batches = len(val_keys)\n",
    "        self.image_size = image_size\n",
    "        self.color_jitter = []\n",
    "        if saturation_var:\n",
    "            self.saturation_var = saturation_var\n",
    "            self.color_jitter.append(self.saturation)\n",
    "        if brightness_var:\n",
    "            self.brightness_var = brightness_var\n",
    "            self.color_jitter.append(self.brightness)\n",
    "        if contrast_var:\n",
    "            self.contrast_var = contrast_var\n",
    "            self.color_jitter.append(self.contrast)\n",
    "        self.lighting_std = lighting_std\n",
    "        self.hflip_prob = hflip_prob\n",
    "        self.vflip_prob = vflip_prob\n",
    "        self.do_crop = do_crop\n",
    "        self.crop_area_range = crop_area_range\n",
    "        self.aspect_ratio_range = aspect_ratio_range\n",
    "\n",
    "    def grayscale(self, rgb):\n",
    "        return rgb.dot([0.299, 0.587, 0.114])\n",
    "\n",
    "    def saturation(self, rgb):\n",
    "        gs = self.grayscale(rgb)\n",
    "        alpha = 2 * np.random.random() * self.saturation_var \n",
    "        alpha += 1 - self.saturation_var\n",
    "        rgb = rgb * alpha + (1 - alpha) * gs[:, :, None]\n",
    "        return np.clip(rgb, 0, 255)\n",
    "\n",
    "    def brightness(self, rgb):\n",
    "        alpha = 2 * np.random.random() * self.brightness_var \n",
    "        alpha += 1 - self.saturation_var\n",
    "        rgb = rgb * alpha\n",
    "        return np.clip(rgb, 0, 255)\n",
    "\n",
    "    def contrast(self, rgb):\n",
    "        gs = self.grayscale(rgb).mean() * np.ones_like(rgb)\n",
    "        alpha = 2 * np.random.random() * self.contrast_var \n",
    "        alpha += 1 - self.contrast_var\n",
    "        rgb = rgb * alpha + (1 - alpha) * gs\n",
    "        return np.clip(rgb, 0, 255)\n",
    "\n",
    "    def lighting(self, img):\n",
    "        cov = np.cov(img.reshape(-1, 3) / 255.0, rowvar=False)\n",
    "        eigval, eigvec = np.linalg.eigh(cov)\n",
    "        noise = np.random.randn(3) * self.lighting_std\n",
    "        noise = eigvec.dot(eigval * noise) * 255\n",
    "        img += noise\n",
    "        return np.clip(img, 0, 255)\n",
    "\n",
    "    def horizontal_flip(self, img, y):\n",
    "        if np.random.random() < self.hflip_prob:\n",
    "            img = img[:, ::-1]\n",
    "            y[:, [0, 2]] = 1 - y[:, [2, 0]]\n",
    "        return img, y\n",
    "\n",
    "    def vertical_flip(self, img, y):\n",
    "        if np.random.random() < self.vflip_prob:\n",
    "            img = img[::-1]\n",
    "            y[:, [1, 3]] = 1 - y[:, [3, 1]]\n",
    "        return img, y\n",
    "\n",
    "    def random_sized_crop(self, img, targets):\n",
    "        img_w = img.shape[1]\n",
    "        img_h = img.shape[0]\n",
    "        img_area = img_w * img_h\n",
    "        random_scale = np.random.random()\n",
    "        random_scale *= (self.crop_area_range[1] -\n",
    "                         self.crop_area_range[0])\n",
    "        random_scale += self.crop_area_range[0]\n",
    "        target_area = random_scale * img_area\n",
    "        random_ratio = np.random.random()\n",
    "        random_ratio *= (self.aspect_ratio_range[1] -\n",
    "                         self.aspect_ratio_range[0])\n",
    "        random_ratio += self.aspect_ratio_range[0]\n",
    "        w = np.round(np.sqrt(target_area * random_ratio))     \n",
    "        h = np.round(np.sqrt(target_area / random_ratio))\n",
    "        if np.random.random() < 0.5:\n",
    "            w, h = h, w\n",
    "        w = min(w, img_w)\n",
    "        w_rel = w / img_w\n",
    "        w = int(w)\n",
    "        h = min(h, img_h)\n",
    "        h_rel = h / img_h\n",
    "        h = int(h)\n",
    "        x = np.random.random() * (img_w - w)\n",
    "        x_rel = x / img_w\n",
    "        x = int(x)\n",
    "        y = np.random.random() * (img_h - h)\n",
    "        y_rel = y / img_h\n",
    "        y = int(y)\n",
    "        img = img[y:y+h, x:x+w]\n",
    "        new_targets = []\n",
    "        for box in targets:\n",
    "            cx = 0.5 * (box[0] + box[2])\n",
    "            cy = 0.5 * (box[1] + box[3])\n",
    "            if (x_rel < cx < x_rel + w_rel and\n",
    "                y_rel < cy < y_rel + h_rel):\n",
    "                xmin = (box[0] - x_rel) / w_rel\n",
    "                ymin = (box[1] - y_rel) / h_rel\n",
    "                xmax = (box[2] - x_rel) / w_rel\n",
    "                ymax = (box[3] - y_rel) / h_rel\n",
    "                xmin = max(0, xmin)\n",
    "                ymin = max(0, ymin)\n",
    "                xmax = min(1, xmax)\n",
    "                ymax = min(1, ymax)\n",
    "                box[:4] = [xmin, ymin, xmax, ymax]\n",
    "                new_targets.append(box)\n",
    "        new_targets = np.asarray(new_targets).reshape(-1, targets.shape[1])\n",
    "        return img, new_targets\n",
    "\n",
    "    def generate(self, train=True):\n",
    "        while True:\n",
    "            if train:\n",
    "                shuffle(self.train_keys)\n",
    "                keys = self.train_keys\n",
    "            else:\n",
    "                shuffle(self.val_keys)\n",
    "                keys = self.val_keys\n",
    "            inputs = []\n",
    "            targets = []\n",
    "            for key in keys:            \n",
    "                img_path = self.path_prefix + key\n",
    "                img = imread(img_path).astype('float32')\n",
    "                y = self.gt[key].copy()\n",
    "                if train and self.do_crop:\n",
    "                    img, y = self.random_sized_crop(img, y)\n",
    "                img = imresize(img, self.image_size).astype('float32')\n",
    "                # img = np.array(img.fromarray(arr).resize(self.image_size))\n",
    "                # boxの位置は正規化されているから画像をリサイズしても\n",
    "                # 教師信号としては問題ない\n",
    "                if train:\n",
    "                    shuffle(self.color_jitter)\n",
    "                    for jitter in self.color_jitter:\n",
    "                        img = jitter(img)\n",
    "                    if self.lighting_std:\n",
    "                        img = self.lighting(img)\n",
    "                    if self.hflip_prob > 0:\n",
    "                        img, y = self.horizontal_flip(img, y)\n",
    "                    if self.vflip_prob > 0:\n",
    "                        img, y = self.vertical_flip(img, y)\n",
    "                # 訓練データ生成時にbbox_utilを使っているのはここだけらしい\n",
    "                #print(y)\n",
    "                y = self.bbox_util.assign_boxes(y)\n",
    "                #print(y)\n",
    "                inputs.append(img)                \n",
    "                targets.append(y)\n",
    "                if len(targets) == self.batch_size:\n",
    "                    tmp_inp = np.array(inputs)\n",
    "                    tmp_targets = np.array(targets)\n",
    "                    inputs = []\n",
    "                    targets = []\n",
    "                    yield preprocess_input(tmp_inp), tmp_targets\n",
    "\n",
    "# path_prefix = './JPEGImages/'\n",
    "path_prefix = './JPEGImages/'\n",
    "gen = Generator(gt, bbox_util, 4, path_prefix,\n",
    "                train_keys, val_keys,\n",
    "                (input_shape[0], input_shape[1]), do_crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "colab_type": "code",
    "id": "fqMIz0Ni4iJ2",
    "outputId": "17668bb2-07cb-4bee-f7e0-9a3e387ce4d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 03:13:33.207831 4489672128 deprecation_wrapper.py:119] From /Users/cyberbrain/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0719 03:13:33.208822 4489672128 deprecation_wrapper.py:119] From /Users/cyberbrain/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_1\", padding=\"same\")`\n",
      "W0719 03:13:33.211991 4489672128 deprecation_wrapper.py:119] From /Users/cyberbrain/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0719 03:13:33.223516 4489672128 deprecation_wrapper.py:119] From /Users/cyberbrain/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0719 03:13:33.224215 4489672128 deprecation_wrapper.py:119] From /Users/cyberbrain/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_2\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool1\", padding=\"same\")`\n",
      "W0719 03:13:33.283055 4489672128 deprecation_wrapper.py:119] From /Users/cyberbrain/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_1\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_2\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool2\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_1\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_2\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_3\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool3\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_1\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_2\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_3\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool4\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_1\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_2\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_3\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:102: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(1, 1), name=\"pool5\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/keras/legacy/layers.py:304: UserWarning: The `AtrousConvolution2D` layer  has been deprecated. Use instead the `Conv2D` layer with the `dilation_rate` argument.\n",
      "  warnings.warn('The `AtrousConvolution2D` layer '\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/keras/legacy/layers.py:308: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\", name=\"fc6\", dilation_rate=(6, 6), padding=\"same\")`\n",
      "  return Conv2D(*args, **kwargs)\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:110: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), activation=\"relu\", name=\"fc7\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:115: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", name=\"conv6_1\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv6_2\", strides=(2, 2), padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:122: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv7_1\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:126: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv7_2\", strides=(2, 2), padding=\"valid\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv8_1\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:133: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv8_2\", strides=(2, 2), padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:140: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"conv4_3_norm_mbox_loc\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:148: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(63, (3, 3), name=\"conv4_3_norm_mbox_conf\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"fc7_mbox_loc\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:168: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"fc7_mbox_conf\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:178: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv6_2_mbox_loc\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:186: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv6_2_mbox_conf\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:197: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv7_2_mbox_loc\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:205: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv7_2_mbox_conf\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:216: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv8_2_mbox_loc\", padding=\"same\")`\n",
      "/Users/cyberbrain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:224: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv8_2_mbox_conf\", padding=\"same\")`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer #1 (named \"conv1_1\"), weight <tf.Variable 'conv1_1/kernel:0' shape=(3, 3, 300, 64) dtype=float32_ref> has shape (3, 3, 300, 64), but the saved weight has shape (3, 3, 3, 64).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-db199cf021bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSD300\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weights_SSD300.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 saving.load_weights_from_hdf5_group_by_name(\n\u001b[1;32m   1162\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_mismatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m                     reshape=reshape)\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                                          \u001b[0;34m' has shape {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                                          \u001b[0;34m', but the saved weight has shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m                                          str(weight_values[i].shape) + '.')\n\u001b[0m\u001b[1;32m   1150\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     weight_value_tuples.append((symbolic_weights[i],\n",
      "\u001b[0;31mValueError\u001b[0m: Layer #1 (named \"conv1_1\"), weight <tf.Variable 'conv1_1/kernel:0' shape=(3, 3, 300, 64) dtype=float32_ref> has shape (3, 3, 300, 64), but the saved weight has shape (3, 3, 3, 64)."
     ]
    }
   ],
   "source": [
    "model = SSD300(input_shape, num_classes=NUM_CLASSES)\n",
    "model.load_weights('./weights_SSD300.hdf5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "105hTsWyAmPY",
    "outputId": "27c77abd-1e22-489e-93a7-4bec47424a98"
   },
   "outputs": [],
   "source": [
    "freeze = ['input_1', 'conv1_1', 'conv1_2', 'pool1',\n",
    "          'conv2_1', 'conv2_2', 'pool2',\n",
    "          'conv3_1', 'conv3_2', 'conv3_3', 'pool3']#,\n",
    "#           'conv4_1', 'conv4_2', 'conv4_3', 'pool4']\n",
    "\n",
    "for L in model.layers:\n",
    "    if L.name in freeze:\n",
    "        L.trainable = False\n",
    "\n",
    "def schedule(epoch, decay=0.9):\n",
    "    return base_lr * decay**(epoch)\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint('./checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                                             verbose=1,\n",
    "                                             save_weights_only=True),\n",
    "             keras.callbacks.LearningRateScheduler(schedule)]\n",
    "\n",
    "base_lr = 3e-4\n",
    "optim = keras.optimizers.Adam(lr=base_lr)\n",
    "model.compile(optimizer=optim,\n",
    "              loss=MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss)\n",
    "\n",
    "# nb_epoch = 2\n",
    "# history = model.fit_generator(gen.generate(True), gen.train_batches,\n",
    "#                               nb_epoch, verbose=1,\n",
    "#                               callbacks=callbacks,\n",
    "#                               validation_data=gen.generate(False),\n",
    "#                               nb_val_samples=gen.val_batches,\n",
    "#                               nb_worker=1)\n",
    "# epochs = 2\n",
    "# batch_size=4 #例\n",
    "# history = model.fit_generator(gen.generate(True), \n",
    "#                      steps_per_epoch =gen.train_batches//batch_size,\n",
    "#                               epochs=epochs, \n",
    "#                               verbose=1,\n",
    "#                               callbacks=callbacks,\n",
    "#                               validation_data=gen.generate(False),\n",
    "#                               validation_steps=gen.val_batches, workers=1)\n",
    "\n",
    "nb_epoch = 10\n",
    "history = model.fit_generator(gen.generate(True), gen.train_batches,\n",
    "                              nb_epoch, verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=gen.generate(False),\n",
    "                              nb_val_samples=gen.val_batches,\n",
    "                              workers=1)\n",
    "\n",
    "            \n",
    "inputs = []\n",
    "images = []\n",
    "img_path = path_prefix + sorted(val_keys)[0]\n",
    "img = image.load_img(img_path, target_size=(300, 300))\n",
    "img = image.img_to_array(img)\n",
    "images.append(imread(img_path))\n",
    "inputs.append(img.copy())\n",
    "inputs = preprocess_input(np.array(inputs))\n",
    "\n",
    "preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "results = bbox_util.detection_out(preds)\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    # Parse the outputs.\n",
    "    det_label = results[i][:, 0]\n",
    "    det_conf = results[i][:, 1]\n",
    "    det_xmin = results[i][:, 2]\n",
    "    det_ymin = results[i][:, 3]\n",
    "    det_xmax = results[i][:, 4]\n",
    "    det_ymax = results[i][:, 5]\n",
    "\n",
    "    # Get detections with confidence higher than 0.6.\n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.6]\n",
    "\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, NUM_CLASSES)).tolist()\n",
    "\n",
    "    plt.imshow(img / 255.)\n",
    "    currentAxis = plt.gca()\n",
    "\n",
    "    for i in range(top_conf.shape[0]):\n",
    "        xmin = int(round(top_xmin[i] * img.shape[1]))\n",
    "        ymin = int(round(top_ymin[i] * img.shape[0]))\n",
    "        xmax = int(round(top_xmax[i] * img.shape[1]))\n",
    "        ymax = int(round(top_ymax[i] * img.shape[0]))\n",
    "        score = top_conf[i]\n",
    "        label = int(top_label_indices[i])\n",
    "        # label_name = voc_classes[label - 1]\n",
    "        display_txt = '{:0.2f}, {}'.format(score, label)\n",
    "        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "        color = colors[label]\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqWzQkmUB9QK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SSD_training_aiacademy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
